{"text": "<bos>\nChapter 11\nSorting and\nSearching\nAlgorithms\nChapter 11:\nSorting and Searching\nAlgorithms\n11.1 – Sorting\n11.2 – Simple Sorts\n11.3 – O(N log N) Sorts\n2\n11.4 – More Sorting Considerations\n11.5 – Searching\n11.1 Sorting\n• Putting an unsorted list of data elements into\norder – sorting - is a very common and useful\noperation\n• We describe efficiency by relating the number of\ncomparisons to the number of elements in the\nlist (N)\nA Test Harness\n• To help us test our sorting algorithms we create an\napplication class called Sorts:\n• The class defines an array values that can hold 50\nintegers and static methods:\n– initValues: Initializes the values array with random numbers\nbetween 0 and 99\n– isSorted: Returns a boolean value indicating whether the\nvalues array is currently sorted\n– swap: swaps the\n<eos>"}
{"text": "<bos>\nintegers between values[index1] and\nvalues[index2], where index1 and index2 are parameters\nof the method\n– printValues: Prints the contents of the values array to the\nSystem.out stream; the output is arranged evenly in ten\ncolumns\nExample of Sorts main method\npublic static void main(String[] args) throws IOException\n{\ninitValues();\nprintValues();\nSystem.out.println(\"values is sorted: \" + isSorted());\nSystem.out.println();\nswap(0, 1); // normally we put sorting algorithm here\nprintValues();\nSystem.out.println(\"values is sorted: \" + isSorted());\nSystem.out.println();\n}\nOutput from Example\nthe values array is:\n20 49 07 50 45 69 20 07 88 02\n89 87 35 98 23 98 61 03 75 48 This part varies\n25 81 97 79 40 78 47 56 24 07 for each sample run\n63 39 52 80 11 63 51 45 25 78\n35 62 72 05 98 83 05 14 30\n<eos>"}
{"text": "<bos>\n23\nvalues is sorted: false\nthe values array is:\n49 20 07 50 45 69 20 07 88 02\n89 87 35 98 23 98 61 03 75 48\nThis does to, of course\n25 81 97 79 40 78 47 56 24 07\n63 39 52 80 11 63 51 45 25 78\n35 62 72 05 98 83 05 14 30 23\nvalues is sorted: false\n11.2 Simple Sorts\n• In this section we present three “simple” sorts\n– Selection Sort\n– Bubble Sort\n– Insertion Sort\n• Properties of these sorts\n– use an unsophisticated brute force approach\n– are not very efficient\n– are easy to understand and to implement\nSelection Sort\n• This algorithm was introduced in Section 1.6,\n\"Comparing Algorithms\"\n• If handed a list of names on a sheet of paper\nand asked to put them in alphabetical order, we\nmight use this general approach:\n– Select the name that comes first in alphabetical order,\nand write it on a second\n<eos>"}
{"text": "<bos>\nsheet of paper.\n– Cross the name out on the original sheet.\n– Repeat steps 1 and 2 for the second name, the third\nname, and so on until all the names on the original\nsheet have been crossed out and written onto the\nsecond sheet.\nAn improvement\n• Our algorithm is simple but it has one drawback:\nIt requires space to store two complete lists.\n• Instead of writing the “first” name onto a\nseparate sheet of paper, exchange it with the\nname in the first location on the original sheet.\nAnd so on.\nSelection Sort Algorithm\nSelectionSort\nfor current going from 0 to SIZE - 2\nFind the index in the array of the smallest unsorted element\nSwap the current element with the smallest unsorted one\nAn example is depicted on the following slide …\nSelection Sort Snapshot\nSelection Sort Code\nstatic int\n<eos>"}
{"text": "<bos>\nminIndex(int startIndex, int endIndex)\n// Returns the index of the smallest value in\n// values[startIndex]..values[endIndex].\n{\nint indexOfMin = startIndex;\nfor (int index = startIndex + 1; index <= endIndex; index++)\nif (values[index] < values[indexOfMin])\nindexOfMin = index;\nreturn indexOfMin;\n}\nstatic void selectionSort()\n// Sorts the values array using the selection sort algorithm.\n{\nint endIndex = SIZE – 1;\nfor (int current = 0; current < endIndex; current++)\nswap(current, minIndex(current, endIndex));\n}\nTesting\nSelection\nThe resultant output:\nSort\nthe values array is:\n92 66 38 17 21 78 10 43 69 19\n17 96 29 19 77 24 47 01 97 91\n13 33 84 93 49 85 09 54 13 06\nThe test harness:\n21 21 93 49 67 42 25 29 05 74\n96 82 26 25 11 74 03 76 29 10\ninitValues();\nprintValues(); values is sorted:\n<eos>"}
{"text": "<bos>\nfalse\nSystem.out.println(\"values is sorted: \"\n+ isSorted()); Selection Sort called\nSystem.out.println(); the values array is:\n01 03 05 06 09 10 10 11 13 13\nselectionSort(); 17 17 19 19 21 21 21 24 25 25\n26 29 29 29 33 38 42 43 47 49\nSystem.out.println(\"Selection Sort called\\n\"); 49 54 66 67 69 74 74 76 77 78\nprintValues(); 82 84 85 91 92 93 93 96 96 97\nSystem.out.println(\"values is sorted: \"\n+ isSorted()); values is sorted: true\nSystem.out.println();\nSelection Sort Analysis\n• We describe the number of comparisons as a function of\nthe number of elements in the array, i.e., SIZE. To be\nconcise, in this discussion we refer to SIZE as N\n• The minIndex method is called N - 1 times\n• Within minIndex, the number of comparisons varies:\n– in the first call there are N - 1 comparisons\n– in the next\n<eos>"}
{"text": "<bos>\ncall there are N - 2 comparisons\n– and so on, until in the last call, when there is only 1 comparison\n• The total number of comparisons is\n(N – 1) + (N – 2) + (N – 3) + ... + 1\n= N(N – 1)/2 = 1/2N2 – 1/2N\n• The Selection Sort algorithm is O(N2)\nNumber of Comparisons Required\nto Sort Arrays of Different Sizes\nUsing Selection Sort\nNumber of Elements Number of Comparisons\n10 45\n20 190\n100 4,950\n1,000 499,500\n10,000 49,995,000\nBubble Sort\n• With this approach the smaller data values “bubble up” to the front of\nthe array …\n• Each iteration puts the smallest unsorted element into its correct\nplace, but it also makes changes in the locations of the other\nelements in the array.\n• The first iteration puts the smallest element in the array into the first\narray position:\n– starting with the last\n<eos>"}
{"text": "<bos>\narray element, we compare successive pairs of\nelements, swapping whenever the bottom element of the pair is smaller\nthan the one above it\n– in this way the smallest element “bubbles up” to the top of the array.\n• The next iteration puts the smallest element in the unsorted part of\nthe array into the second array position, using the same technique\n• The rest of the sorting process continues in the same way\nBubble Sort Algorithm\nBubbleSort\nSet current to the index of first element in the array\nwhile more elements in unsorted part of array\n“Bubble up” the smallest element in the unsorted part,\ncausing intermediate swaps as needed\nShrink the unsorted part of the array by incrementing current\nbubbleUp(startIndex, endIndex)\nfor index going from endIndex DOWNTO startIndex +1\nif values[index] <\n<eos>"}
{"text": "<bos>\nvalues[index - 1]\nSwap the value at index with the value at index - 1\nAn example is depicted on the following slide …\nBubble Sort Snapshot\nBubble Sort Code\nstatic void bubbleUp(int startIndex, int endIndex)\n// Switches adjacent pairs that are out of order\n// between values[startIndex]..values[endIndex]\n// beginning at values[endIndex].\n{\nfor (int index = endIndex; index > startIndex; index--)\nif (values[index] < values[index – 1])\nswap(index, index – 1);\n}\nstatic void bubbleSort()\n// Sorts the values array using the bubble sort algorithm.\n{\nint current = 0;\nwhile (current < SIZE – 1)\n{\nbubbleUp(current, SIZE – 1);\ncurrent++;\n}\n}\nBubble Sort Analysis\n• Analyzing the work required by bubbleSort is\nthe same as for the selection sort algorithm.\n• The comparisons are in bubbleUp, which is\n<eos>"}
{"text": "<bos>\ncalled N – 1 times.\n• There are N – 1 comparisons the first time, N – 2\ncomparisons the second time, and so on.\n• Therefore, bubbleSort and selectionSort\nrequire the same amount of work in terms of the\nnumber of comparisons.\n• The Bubble Sort algorithm is O(N2)\nInsertion Sort\n• In Section 6.4, “Sorted Array-Based List Implementation,” we\ndescribed the Insertion Sort algorithm and how it could be used to\nmaintain a list in sorted order. Here we present essentially the same\nalgorithm.\n• Each successive element in the array to be sorted is inserted into its\nproper place with respect to the other, already sorted elements.\n• As with the previous sorts, we divide our array into a sorted part and\nan unsorted part.\n– Initially, the sorted portion contains only one element: the first element\nin the\n<eos>"}
{"text": "<bos>\narray.\n– Next we take the second element in the array and put it into its correct\nplace in the sorted part; that is, values[0] and values[1] are in order with\nrespect to each other.\n– Next the value in values[2] is put into its proper place, so\nvalues[0]..values[2] are in order with respect to each other.\n– This process continues until all the elements have been sorted.\nInsertion Sort Algorithm\ninsertionSort\nfor count going from 1 through SIZE - 1\ninsertElement(0, count)\nInsertElement(startIndex, endIndex)\nSet finished to false\nSet current to endIndex\nSet moreToSearch to true\nwhile moreToSearch AND NOT finished\nif values[current] < values[current - 1]\nswap(values[current], values[current - 1])\nDecrement current\nSet moreToSearch to (current does not equal startIndex)\nelse\nSet finished to\n<eos>"}
{"text": "<bos>\ntrue\nAn example is depicted on the following slide …\nInsertion Sort Snapshot\nInsertion Sort Code\nstatic void insertElement(int startIndex, int endIndex)\n// Upon completion, values[0]..values[endIndex] are sorted.\n{\nboolean finished = false;\nint current = endIndex;\nboolean moreToSearch = true;\nwhile (moreToSearch && !finished)\n{\nif (values[current] < values[current – 1])\n{\nswap(current, current – 1);\ncurrent--;\nmoreToSearch = (current != startIndex);\n}\nelse\nfinished = true;\n}\n}\nstatic void insertionSort()\n// Sorts the values array using the insertion sort algorithm.\n{\nfor (int count = 1; count < SIZE; count++)\ninsertElement(0, count);\n}\nInsertion Sort Analysis\n• The general case for this algorithm mirrors the\nselectionSort and the bubbleSort, so the\ngeneral case is O(N2) .\n• But\n<eos>"}
{"text": "<bos>\ninsertionSort has a “best” case: The\ndata are already sorted in ascending order\n– insertElement is called N times, but only one\ncomparison is made each time and no swaps are\nnecessary.\n• The maximum number of comparisons is made\nonly when the elements in the array are in\nreverse order.\n11.3 O(N log N) Sorts\n2\n• O(N2) sorts and are very time consuming for\nsorting large arrays.\n• Several sorting methods that work better when N\nis large are presented in this section.\n• The efficiency of these algorithms is achieved at\nthe expense of the simplicity seen in the\nselection, bubble, and insertion sorts.\nThe Merge Sort\n• The sorting algorithms covered in Section 10.2\nare all O(N2).\n• Note that N2 is a lot larger than\n(1/2N)2 + (1/2N)2 = 1/2N2\n• If we can cut the array into two pieces, sort each\n<eos>"}
{"text": "<bos>\nsegment, and then merge the two back together,\nwe should end up sorting the entire array with a\nlot less work.\nRationale for Divide and Conquer\nMerge Sort Algorithm\nmergeSort\nCut the array in half\nSort the left half\nSort the right half\nMerge the two sorted halves into one sorted array\nBecause mergeSort is itself a sorting algorithm, we might as well\nuse it to sort the two halves.\nWe can make mergeSort a recursive method and let it call itself\nto sort each of the two subarrays:\nmergeSort—Recursive\nCut the array in half\nmergeSort the left half\nmergeSort the right half\nMerge the two sorted halves into one sorted array\nMerge Sort Summary\nMethod mergeSort(first, last)\nDefinition: Sorts the array elements in ascending order.\nSize: last - first + 1\nBase Case: If size less than 2, do nothing.\n<eos>"}
{"text": "<bos>\nGeneral Case: Cut the array in half.\nmergeSort the left half.\nmergeSort the right half.\nMerge the sorted halves into one sorted array.\nStrategy\nfor\nmerging\ntwo\nsorted\narrays\nOur actual merge problem\nOur solution\nThe merge algorithm\nmerge (leftFirst, leftLast, rightFirst, rightLast)\n(uses a local array, tempArray)\nSet index to leftFirst\nwhile more elements in left half AND more elements in right half\nif values[leftFirst] < values[rightFirst]\nSet tempArray[index] to values[leftFirst]\nIncrement leftFirst\nelse\nSet tempArray[index] to values[rightFirst]\nIncrement rightFirst\nIncrement index\nCopy any remaining elements from left half to tempArray\nCopy any remaining elements from right half to tempArray\nCopy the sorted elements from tempArray back into values\nThe mergeSort method\nThe code for\n<eos>"}
{"text": "<bos>\nmerge follows the algorithm on the previous slide.\nmerge does most of the work!\nHere is mergeSort:\nstatic void mergeSort(int first, int last)\n// Sorts the values array using the merge sort algorithm.\n{\nif (first < last)\n{\nint middle = (first + last) / 2;\nmergeSort(first, middle);\nmergeSort(middle + 1, last);\nmerge(first, middle, middle + 1, last);\n}\n}\nAnalysing Merge Sort\nAnalyzing Merge Sort\n• The total work needed to divide the array in half, over\nand over again until we reach subarrays of size 1, is\nO(N).\n• It takes O(N) total steps to perform merging at each\n“level” of merging.\n• The number of levels of merging is equal to the number\nof times we can split the original array in half\n– If the original array is size N, we have log N levels. (This is the\n2\nsame as the analysis of the\n<eos>"}
{"text": "<bos>\nbinary search algorithm in Section\n1.6.)\n• Because we have log N levels, and we require O(N)\n2\nsteps at each level, the total cost of the merge operation\nis: O(N log N).\n2\n• Because the splitting phase was only O(N), we conclude\nthat Merge Sort algorithm is O(N log N).\n2\nComparing N2 and N log N\n2\nN log N N2 N log N\n2 2\n32 5 1,024 160\n64 6 4.096 384\n128 7 16,384 896\n256 8 65,536 2,048\n512 9 262,144 4,608\n1024 10 1,048,576 10,240\n2048 11 4,194,304 22,528\n4096 12 16,777,216 49,152\nDrawback of Merge Sort\n• A disadvantage of mergeSort is that it requires\nan auxiliary array that is as large as the original\narray to be sorted.\n• If the array is large and space is a critical factor,\nthis sort may not be an appropriate choice.\n• Next we discuss two O(N log N) sorts that move\n2\nelements around in\n<eos>"}
{"text": "<bos>\nthe original array and do not\nneed an auxiliary array.\nQuick Sort\n• A divide-and-conquer algorithm\n• Inherently recursive\n• At each stage the part of the array being sorted is divided into two\n“piles”, with everything in the left pile less than everything in the right\npile\n• The same approach is used to sort each of the smaller piles (a\nsmaller case).\n• This process goes on until the small piles do not need to be further\ndivided (the base case).\nQuick Sort Summary\nMethod quickSort (first, last)\nDefinition: Sorts the elements in sub array values[first]..values[last].\nSize: last - first + 1\nBase Case: If size less than 2, do nothing.\nGeneral Case: Split the array according to splitting value.\nquickSort the elements <= splitting value.\nquickSort the elements > splitting value.\nThe Quick Sort\n<eos>"}
{"text": "<bos>\nAlgorithm\nquickSort\nif there is more than one element in values[first]..values[last]\nSelect splitVal\nSplit the array so that\nvalues[first]..values[splitPoint – 1] <= splitVal\nvalues[splitPoint] = splitVal\nvalues[splitPoint + 1]..values[last] > splitVal\nquickSort the left sub array\nquickSort the right sub array\nThe algorithm depends on the selection of a “split value”,\ncalled splitVal, that is used to divide the array into two\nsub arrays.\nHow do we select splitVal?\nOne simple solution is to use the value in values[first]\nas the splitting value.\nQuick Sort Steps\nThe quickSort method\nstatic void quickSort(int first, int last)\n{\nif (first < last)\n{\nint splitPoint;\nsplitPoint = split(first, last);\n// values[first]..values[splitPoint – 1] <= splitVal\n// values[splitPoint] = splitVal\n//\n<eos>"}
{"text": "<bos>\nvalues[splitPoint+1]..values[last] > splitVal\nquickSort(first, splitPoint – 1);\nquickSort(splitPoint + 1, last);\n}\n}\nThe split\noperation\nThe code for split\nis on page 650\nAnalyzing Quick Sort\n• On the first call, every element in the array is\ncompared to the dividing value (the “split value”),\nso the work done is O(N).\n• The array is divided into two sub arrays (not\nnecessarily halves)\n• Each of these pieces is then divided in two, and\nso on.\n• If each piece is split approximately in half, there\nare O(log N) levels of splits. At each level, we\n2\nmake O(N) comparisons.\n• So Quick Sort is an O(N log N) algorithm.\n2\nDrawbacks of Quick Sort\n• Quick Sort isn’t always quicker.\n– There are log N levels of splits if each split divides the segment\n2\nof the array approximately in half. As we’ve\n<eos>"}
{"text": "<bos>\nseen, the array\ndivision of Quick Sort is sensitive to the order of the data, that is,\nto the choice of the splitting value.\n– If the splits are very lopsided, and the subsequent recursive calls\nto quickSort also result in lopsided splits, we can end up with a\nsort that is O(N2).\n• What about space requirements?\n– There can be many levels of recursion “saved” on the system\nstack at any time.\n– On average, the algorithm requires O(log N) extra space to hold\n2\nthis information and in the worst case requires O(N) extra space,\nthe same as Merge Sort.\nQuick Sort\n• Despite the drawbacks remember that Quick\nSort is VERY quick for large collections of\nrandom data\nHeap Sort\n• In Chapter 9, we discussed the heap - because\nof its order property, the maximum value of a\nheap is in the root node.\n• The\n<eos>"}
{"text": "<bos>\ngeneral approach of the Heap Sort is as\nfollows:\n– take the root (maximum) element off the heap, and\nput it into its place.\n– reheap the remaining elements. (This puts the next-\nlargest element into the root position.)\n– repeat until there are no more elements.\n• For this to work we must first arrange the original\narray into a heap\nBuilding a\nheap\nbuildHeap\nfor index going from first nonleaf node up to the root node\nreheapDown(values[index], index)\nSee next slide …\nThe changing contents of the array\nThe Sort Nodes algorithm\nSort Nodes\nfor index going from last node up to next-to-root node\nSwap data in root node with values[index]\nreheapDown(values[0], 0, index 2 1)\nThe heapSort method\nstatic void heapSort()\n// Post: The elements in the array values are sorted by key\n{\nint index;\n// Convert\n<eos>"}
{"text": "<bos>\nthe array of values into a heap\nfor (index = SIZE/2 – 1; index >= 0; index--)\nreheapDown(values[index], index, SIZE – 1);\n// Sort the array\nfor (index = SIZE – 1; index >=1; index--)\n{\nswap(0, index);\nreheapDown(values[0], 0, index – 1);\n}\n}\nAnalysis of Heap Sort\n• Consider the sorting loop\n– it loops through N ─ 1 times, swapping elements and reheaping\n– the comparisons occur in reheapDown (actually in its helper\nmethod newHole)\n– a complete binary tree with N nodes has O(log (N + 1)) levels\n2\n– in the worst cases, then, if the root element had to be bumped\ndown to a leaf position, the reheapDown method would make\nO(log N) comparisons.\n2\n– so method reheapDown is O(log2N)\n– multiplying this activity by the N ─ 1 iterations shows that the\nsorting loop is O(N log N).\n2\n• Combining the\n<eos>"}
{"text": "<bos>\noriginal heap build, which is O(N), and\nthe sorting loop, we can see that Heap Sort requires O(N\nlog N) comparisons.\n2\nThe Heap Sort\n• For small arrays, heapSort is not very efficient\nbecause of all the “overhead.”\n• For large arrays, however, heapSort is very\nefficient.\n• Unlike Quick Sort, Heap Sort’s efficiency is not\naffected by the initial order of the elements.\n• Heap Sort is also efficient in terms of space – it\nonly requires constant extra space.\n• Heap Sort is an elegant, fast, robust, space\nefficient algorithm!\nComparison of Sorting\nAlgorithms\n11.4 More Sorting Considerations\n• In this section we wrap up our coverage of\nsorting by\n– revisiting testing\n– revisiting efficiency\n– discussing special concerns involved with\nsorting objects rather than primitive types\n– considering the\n<eos>"}
{"text": "<bos>\n“stability” of sorting algorithms\nTesting\n• To thoroughly test our sorting methods we\nshould\n– vary the size of the array\n– vary the original order of the array\n• Random order\n• Reverse order\n• Almost sorted\n• All identical elements\nEfficiency\n• When N is small the simple sorts may be more\nefficient than the “fast” sorts because they\nrequire less overhead.\n• Sometimes it may be desirable, for efficiency\nconsiderations, to streamline the code as much\nas possible, even at the expense of readability.\nFor instance, instead of using a swap method\ndirectly code the swap operation within the\nsorting method.\nSpecial Concerns when Sorting\nObjects\n• When sorting an array of objects we are\nmanipulating references to the object, and not\nthe objects themselves\nStability of a Sorting Algorithm\n• Stable\n<eos>"}
{"text": "<bos>\nSort: A sorting algorithm that preserves\nthe order of duplicates\n• Of the sorts that we have discussed in this book,\nonly heapSort and quickSort are inherently\nunstable\n11.5 Searching\n• This section reviews material scattered\nthroughout the text related to searching.\n• Here we bring these topics together to be\nconsidered in relationship to each other to gain\nan overall perspective.\n• Searching is a crucially important information\nprocessing activity. Options are closely related\nto the way data is structured and organized.\nSequential Searching\n• If we want to add elements as quickly as possible to a\ncollection, and we are not as concerned about how long\nit takes to find them we would put the element\n– into the last slot in an array-based collection\n– into the first slot in a linked\n<eos>"}
{"text": "<bos>\ncollection\n• To search this collection for the element with a given\nkey, we must use a simple linear (or sequential) search\n– Beginning with the first element in the collection, we search for\nthe desired element by examining each subsequent element’s\nkey until either the search is successful or the collection is\nexhausted.\n– Based on the number of comparisons this search is O(N)\n– In the worst case we have to make N key comparisons.\n– On the average, assuming that there is an equal probability of\nsearching for any element in the collection, we make N/2\ncomparisons for a successful search\nOrdering\nHigh-Probability\n• Sometimes certain collection elements are in much\ngreater demand than others. We can then improve the\nsearch:\n– Put the most-often-desired elements at the beginning of the\n<eos>"}
{"text": "<bos>\ncollection\n– Using this scheme, we are more likely to make a hit in the first\nfew tries, and rarely do we have to search the whole collection.\n• If the elements in the collection are not static or if we\ncannot predict their relative demand, we can\n– move each element accessed to the front of the collection\n– as an element is found, it is swapped with the element that\nprecedes it\n• collections in which the relative positions of the elements\nare changed in an attempt to improve search efficiency\nare called self-organizing or self-adjusting collections.\nSorted collections\n• If the collection is sorted, a sequential search no longer needs to\nsearch the whole collection to discover that an element does not\nexist. It only needs to search until it has passed the element’s logical\nplace in the\n<eos>"}
{"text": "<bos>\ncollection—that is, until an element with a larger key\nvalue is encountered.\n• Another advantage of linear searching is its simplicity.\n• The binary search is usually faster, however, it is not guaranteed to\nbe faster for searching very small collections.\n• As the number of elements increases, however, the disparity\nbetween the linear search and the binary search grows very quickly.\n• The binary search is appropriate only for collection elements stored\nin a sequential array-based representation.\n• However, the binary search tree allows us to perform a binary\nsearch on a linked data representation\nHashing\n• We end our discussion of search\nalgorithms by pointing out that the hash\ntable approach to storage presented in\nSections 4 through 6 of Chapter 8 allows\nconstant search time in many\n<eos>"}
{"text": "<bos>\nsituations.\n<eos>"}
